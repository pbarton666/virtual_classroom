{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module focuses on linear discriminant analysis (LDA).  Use LDA when the \n",
    "dependent is categorical and independents are continuous.  Use\n",
    "ANOVA when the situation is reversed.  It requires that the IVs are normally\n",
    "distributed (not the case for logistical regression and probit.\n",
    "   \n",
    "The LDA is a form of Bayesian classification.  It models the membership in \n",
    "each class:\n",
    "\n",
    "   P(X|y=k)\n",
    "   \n",
    " ...as a multivariate Gaussian distribution.  X is the IV vector, y is the DV,\n",
    "    k is the class.  Using Bayes' transformation, we can use priors:\n",
    "    \n",
    "    [ P(X|y=k) * P(y=k) ] / [ SUM_over_i { P(X|y=i) * P(y=i)  } ]\n",
    " \n",
    " Full description here: http://scikit-learn.org/stable/modules/lda_qda.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#py_pandas_lda_1.ipynb\n",
    "import numpy as np             \n",
    "import pandas as  pd    \n",
    "import os\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt #data visualization\n",
    "import seaborn as sns\n",
    "\n",
    "import csv\n",
    "import datetime\n",
    "import math\n",
    "%matplotlib inline\n",
    "\n",
    "if '__file__' in dir():\n",
    "    path, _=os.path.split(__file__)  \n",
    "else: path=os.getcwd() \n",
    "\n",
    "datafile='iris.data.csv'  #Fisher's classic\n",
    "filename=os.path.join(path, datafile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slength</th>\n",
       "      <th>swidth</th>\n",
       "      <th>plength</th>\n",
       "      <th>pwidth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.054000</td>\n",
       "      <td>3.758667</td>\n",
       "      <td>1.198667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.433594</td>\n",
       "      <td>1.764420</td>\n",
       "      <td>0.763161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          slength      swidth     plength      pwidth\n",
       "count  150.000000  150.000000  150.000000  150.000000\n",
       "mean     5.843333    3.054000    3.758667    1.198667\n",
       "std      0.828066    0.433594    1.764420    0.763161\n",
       "min      4.300000    2.000000    1.000000    0.100000\n",
       "25%      5.100000    2.800000    1.600000    0.300000\n",
       "50%      5.800000    3.000000    4.350000    1.300000\n",
       "75%      6.400000    3.300000    5.100000    1.800000\n",
       "max      7.900000    4.400000    6.900000    2.500000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a DataFrame object\n",
    "df=pd.read_csv(filename)\n",
    "\n",
    "#dependent and independent variables\n",
    "iv_names=['slength', 'swidth', 'plength', 'pwidth']\n",
    "dv_name='iclass'\n",
    "\n",
    "#take a look at the data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-2fe827271874>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create categorical data descriptions\n",
    "auto_cats=pd.Categorical(df['iclass'])\n",
    "auto_cats.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the categorical codes as a new column\n",
    "df['iclass_ix']=auto_cats.codes\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#have a look at sepal / petal length scatter using  df.plot.scatter() \n",
    "ax=df[df.iclass=='Iris-versicolor'].\\\n",
    "    plot.scatter(x='slength', y='swidth', \n",
    "                 color='yellow', label='versicolor') \n",
    "\n",
    "df[df.iclass=='Iris-setosa'].\\\n",
    "    plot.scatter(x='slength', y='swidth', \n",
    "                 color='red', label='setosa',\n",
    "                 ax=ax)   #use same axes object!\n",
    "\n",
    "df[df.iclass=='Iris-virginica'].\\\n",
    "    plot.scatter(x='slength', y='swidth', \n",
    "                 color='blue', label='virginica', \n",
    "                 ax=ax)    #here, too.\n",
    "\n",
    "ax.set_title(\"scatter\") \n",
    "#ax.figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can also \"throw the spaghetti against the wall\" and look\n",
    "#  at all the scatters and some summary data:\n",
    "pd.plotting.scatter_matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here is Seaborn's rendition\n",
    "sns.set()\n",
    "sns.pairplot(df[['slength', 'swidth', 'plength', 'pwidth', 'iclass']],\n",
    "                 hue=\"iclass\", \n",
    "                 diag_kind=\"kde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tests for distribution (should be normal)\n",
    "#  This uses D'Agostino's K-squared:\n",
    "#     skew_test_z-score ^2 + kurtosis_test_z-score ^2\n",
    "#  \n",
    "#  Test loooks for chi^2 distro w/ 2 df - asks 'is shape about right?'\n",
    "#     H0: distribution is normal  (this is the \"null hypothesis\")\n",
    "\n",
    "p_target=.05   #if the p-value is less that this, we fail the test\n",
    "\n",
    "for iv in iv_names:\n",
    "    data=df[iv]\t\n",
    "    statistic, p =scipy.stats.normaltest(data)\n",
    "    if p<p_target:\n",
    "        result='FAILED. SAD!'\n",
    "    else: result='passed'\n",
    "    print(\"\\tfeature: {:<10} {:<20} p={:<10}\".\\\n",
    "          format(iv, result, round(p,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some visuals ... build up the subplot objects analytically - \n",
    "#loop over our data vectors and create Q-Q charts for each\n",
    "\n",
    "#create a plot object\n",
    "plt.figure()\n",
    "\n",
    "#set up the rows/columns for our plot object\n",
    "cols=3\n",
    "rows=math.ceil(len(iv_names)/cols) \n",
    "\n",
    "row=1; col=1; subplot=1\n",
    "for iv in iv_names:    \n",
    "    data=df[iv]\t                           #grab the data\n",
    "    plt.subplot(rows, cols, subplot)       #create the subplot object\n",
    "    scipy.stats.probplot(data, plot=plt)   #stuff it w/ data\n",
    "    plt.title(iv)                          #give it a nice title\n",
    "    #reset indices \n",
    "    col+=1\n",
    "    if col>cols: \n",
    "        col=1\n",
    "        row+=1\n",
    "    subplot+=1\n",
    "\n",
    "#spruce it up aesthetically \n",
    "fig.canvas.set_window_title(\"Q-Q Charts\")\n",
    "fig=plt.gcf()   #get current figure - figure object is main container\n",
    "plt.tight_layout() #alternative:  plt.subplots_adjust() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lookin' good.  Let's do some analysis\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "#grab the descriptive data\n",
    "raw_data = df[iv_names].values  #a ndarray\n",
    "\n",
    "#create an instance of LDA.  We'll use this object to run\n",
    "#  analysis, test results, store the solved model.\n",
    "lda = LDA(n_components=2)\n",
    "lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use fit() to produce component vectors and transform() to project\n",
    "iclass_ix=pd.Categorical(df[dv_name]).codes\n",
    "\n",
    "#lda.fit(<independent vars, dependent var>)\n",
    "lda_result=lda.fit(raw_data, iclass_ix)    #fit the data\n",
    "lda_result=lda_result.transform(raw_data)  #projection to [x,y]\n",
    "\n",
    "#add results to the DataFrame for future reference\n",
    "df['dim1'] = lda_result[:, 0]\n",
    "df['dim2'] = lda_result[:, 1]\n",
    "\n",
    "#not much to look at, but here are the results\n",
    "lda_result[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so, how did we do?  \n",
    "mean_success_rate=lda.score(raw_data, iclass_ix)\n",
    "print(\"Success rate:\", round(mean_success_rate, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a nice plot of the results\n",
    "\n",
    "#query for the separate iris classes\n",
    "setosa = df.query(\"iclass=='Iris-setosa'\")\n",
    "versicolor = df.query(\"iclass=='Iris-versicolor'\")\n",
    "virginica = df.query(\"iclass=='Iris-virginica'\")\n",
    "\n",
    "#create a new plotting object and load it with KDE (kernel \n",
    "#   density estimate) plots\n",
    "plt.figure()\n",
    "\n",
    "#these are color pallattes known to seaborn (lots of other options)\n",
    "color1=\"Greens\"; color2=\"Purples\"; color3=\"Blues\"\n",
    "\n",
    "ax = sns.kdeplot(setosa.dim1, setosa.dim1, cmap=color1,\n",
    "                 shade=True, shade_lowest=False)\n",
    "ax = sns.kdeplot(versicolor.dim1, versicolor.dim2, cmap=color2,\n",
    "                 shade=True, shade_lowest=False)\n",
    "ax = sns.kdeplot(virginica.dim1, virginica.dim2, cmap=color3,\n",
    "                 shade=True, shade_lowest=False)\n",
    "\n",
    "#create some labels; this picks off the darkest color of each palatte\n",
    "color1 = sns.color_palette(color1)[-1]\n",
    "color2 = sns.color_palette(color2)[-1]\n",
    "color3 = sns.color_palette(color3)[-1]\n",
    "\n",
    "#this places text (x, y, text, color, font size)\n",
    "ax.text(5, 4, \"Iris setosa\", color=color1, size=20)\n",
    "ax.text(0, 0, \"Iris versicolor\", color=color2, size=20)\n",
    "ax.text(-10, 4, \"Iris virginica\", color=color3, size=20)\n",
    "\n",
    "#second arg is a dict that can contain lots of font specs\n",
    "ax.set_title('Linear Discriminant Analysis', {'fontsize':20})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now try on a training set (we'll split it in half)\n",
    "\n",
    "#sklearn.cross_validation.rain_test_split in older versions\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#could do this manually, but it's built-in.  \".5\" makes a 50/50 split\n",
    "train, test=train_test_split(df, test_size=.5)\n",
    "\n",
    "train_data = train[['slength', 'swidth', 'plength', 'pwidth']].values\n",
    "train_class_ix=train['iclass_ix']\n",
    "\n",
    "test_data = test[['slength', 'swidth', 'plength', 'pwidth']].values\n",
    "test_class_ix=test['iclass_ix']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analyze the training data\n",
    "lda = LDA(n_components=2)\n",
    "\n",
    "#use fit() to produce component vectors\n",
    "train_result=lda.fit(train_data, train_class_ix)\n",
    "tlda_result=train_result.transform(train_data)\n",
    "\n",
    "#show the results  \n",
    "train_success_rate=train_result.score(train_data, train_class_ix)\n",
    "print(\"Training success rate:\", round(train_success_rate, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This time using test data against trained model\n",
    "test_success_rate=train_result.score(test_data, test_class_ix)\n",
    "print(\"Test success rate ('naive' data):\", round(test_success_rate, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just for fun, play around with the size of the training set\n",
    "results=[]\n",
    "for training_frac in [.10,.20,.30,.40,.50]:\n",
    "    train, test=train_test_split(df, test_size=training_frac)\n",
    "    lda = LDA(n_components=2)\n",
    "    \n",
    "    train_data = train[['slength', 'swidth', 'plength', 'pwidth']].values\n",
    "    train_class_ix=train['iclass_ix']\n",
    "    \n",
    "    test_data = test[['slength', 'swidth', 'plength', 'pwidth']].values\n",
    "    test_class_ix=test['iclass_ix']\n",
    "    \n",
    "    #use fit() to produce component vectors\n",
    "    train_result=lda.fit(train_data, train_class_ix)\n",
    "    tlda_result=train_result.transform(train_data)\n",
    "    \n",
    "    #so, how did we do?  This time using test data against trained model\n",
    "    test_success_rate=train_result.score(test_data, test_class_ix)\n",
    "    results.append((training_frac, test_success_rate))\n",
    "\n",
    "print(\"results from changing training fraction\")\n",
    "print(\"YMMV as the training set is randomly drawn\\n\")\n",
    "fmt=\"{:<10} {:<10}\"\n",
    "print(fmt.format(\"fraction\", \"score\"))\n",
    "print(fmt.format(\"_\"*10, \"_\"*10))\n",
    "print()\n",
    "\n",
    "for frac, result in results:\n",
    "    print(fmt.format(frac, round(result,2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you can pickle a saved model and rerun it intact:\n",
    "import pickle\n",
    "\n",
    "fn='my_lda_model.pkl'\n",
    "model=train_result\n",
    "\n",
    "#serialize and store\n",
    "with open(fn, 'wb') as f:\n",
    "    pickle.dump(model,f)\n",
    "\n",
    "#kill the original     \n",
    "model=None\n",
    "\n",
    "#reconstitute the Python object\n",
    "with open(fn, 'rb') as f:\n",
    "    model=pickle.load(f)\n",
    "    \n",
    "print(\"recovered model\\n\", repr(model))\n",
    "\n",
    "print(\"Same score?\")\n",
    "reconstituted = model.score(test_data, test_class_ix)\n",
    "original = train_result.score(test_data, test_class_ix)\n",
    "print(\"original: {}   reconstituted: {}\".\\\n",
    "        format(original, reconstituted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
